<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>bioinformatics on Codeless Code</title>
    <link>https://code.lol/categories/bioinformatics/</link>
    <description>Recent content in bioinformatics on Codeless Code</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Fri, 25 Jan 2019 20:35:20 -0500</lastBuildDate><atom:link href="https://code.lol/categories/bioinformatics/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Oriented Bounding-Box Heuristic</title>
      <link>https://code.lol/post/bioinformatics/oriented-bounding-box-heuristic/</link>
      <pubDate>Fri, 25 Jan 2019 20:35:20 -0500</pubDate>
      
      <guid>https://code.lol/post/bioinformatics/oriented-bounding-box-heuristic/</guid>
      <description>The 2-dimensional minimum-area oriented bounding box problem is as follows: Given a set of coplanar points, how can we efficiently find the smallest rectangle which encloses these points? Additionally, that rectangle can be oriented at any angle with respect to the coordinate system.
One interesting estimate for the solution, which guarantees &amp;ldquo;pretty good&amp;rdquo; results in O(n) time is a natural extension of orthogonal linear regression. Specifically, we assume that the minimum rectangle is aligned to the orthogonal &amp;ldquo;line of best fit&amp;rdquo; of the point set.</description>
    </item>
    
    <item>
      <title>One-Dimensional Linear Regression</title>
      <link>https://code.lol/post/bioinformatics/one-dimensional-linear-regression/</link>
      <pubDate>Fri, 25 Jan 2019 18:27:02 -0500</pubDate>
      
      <guid>https://code.lol/post/bioinformatics/one-dimensional-linear-regression/</guid>
      <description>The simple linear regression algorithm is a closed-form solution to a least-squared distance minimization problem. Here is demonstrated the one-dimensional case of simple linear regression.
$$ \min_{\alpha,\beta} \sum_{i=1}^{n} (y_i - \alpha - \beta x_i)^2 $$ Click and drag the black points to affect the regression. Double click to add or remove points. The blue point in the center represents the geometric average, through which the fit always passes through.
In this problem, the least-squared distance considered includes only the vertical component.</description>
    </item>
    
    <item>
      <title>Quadratic Bezier Curves</title>
      <link>https://code.lol/post/bioinformatics/quadratic-bezier-curves/</link>
      <pubDate>Fri, 25 Jan 2019 17:40:45 -0500</pubDate>
      
      <guid>https://code.lol/post/bioinformatics/quadratic-bezier-curves/</guid>
      <description>Quadratic BÃ©zier curves are explicit parametric functions of the following form:
$$ x(t) = (1-t)^2 x_0 + 2t(1-t) x_1 + t^2 x_2\\ y(t) = (1-t)^2 y_0 + 2t(1-t) y_1 + t^2 y_2\\ t \in \mathbb R[0,1] $$ These curves are perhaps the simplest class of parametric curves, but useful in their own right. This is a small demo of such curves.
Drag the control points around to see the curve change.</description>
    </item>
    
  </channel>
</rss>
